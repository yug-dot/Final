{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58891379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Q2: Semantic Understanding & Language Modeling ---\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# 1. Synonyms, Antonyms, Hypernyms\n",
    "word = \"happy\"\n",
    "synonyms, antonyms, hypernyms = set(), set(), set()\n",
    "\n",
    "for syn in wordnet.synsets(word):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.add(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.add(l.antonyms()[0].name())\n",
    "    for h in syn.hypernyms():\n",
    "        for l in h.lemmas():\n",
    "            hypernyms.add(l.name())\n",
    "\n",
    "print(\"Synonyms:\", synonyms)\n",
    "print(\"Antonyms:\", antonyms)\n",
    "print(\"Hypernyms:\", hypernyms)\n",
    "\n",
    "# 2. Simple N-Gram Language Model (Bigram + Laplace)\n",
    "text = \"the cat sat on the mat\"\n",
    "tokens = text.split()\n",
    "bigrams = [(tokens[i], tokens[i+1]) for i in range(len(tokens)-1)]\n",
    "freq = Counter(bigrams)\n",
    "vocab = set(tokens)\n",
    "\n",
    "def prob(w1, w2):\n",
    "    return (freq[(w1, w2)] + 1) / (tokens.count(w1) + len(vocab))\n",
    "\n",
    "print(\"\\nP('sat' | 'cat') =\", prob('cat', 'sat'))\n",
    "\n",
    "\"\"\"\n",
    "Possible Errors & Fixes:\n",
    "1. LookupError: wordnet not found → nltk.download('wordnet')\n",
    "2. ZeroDivisionError → occurs if word not in text\n",
    "3. IndexError → ensure text has enough words for n-grams\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd420c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Q2: Semantic Understanding & Language Modeling ---\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# 1. Synonyms, Antonyms, Hypernyms\n",
    "word = \"good\"\n",
    "synonyms = set()\n",
    "antonyms = set()\n",
    "hypernyms = set()\n",
    "\n",
    "for syn in wordnet.synsets(word):\n",
    "    for lemma in syn.lemmas():\n",
    "        synonyms.add(lemma.name())\n",
    "        if lemma.antonyms():\n",
    "            antonyms.add(lemma.antonyms()[0].name())\n",
    "    for hyper in syn.hypernyms():\n",
    "        hypernyms.update(lemma.name() for lemma in hyper.lemmas())\n",
    "\n",
    "print(\"Synonyms:\", synonyms)\n",
    "print(\"Antonyms:\", antonyms)\n",
    "print(\"Hypernyms:\", hypernyms)\n",
    "\n",
    "# 2. N-Gram Language Model with Laplace Smoothing\n",
    "def generate_ngrams(tokens, n):\n",
    "    return [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "\n",
    "text = \"the cat sat on the mat\"\n",
    "tokens = text.split()\n",
    "n = 2  # bigram\n",
    "ngrams = generate_ngrams(tokens, n)\n",
    "\n",
    "# Frequency counts\n",
    "counts = Counter(ngrams)\n",
    "vocab_size = len(set(tokens))\n",
    "\n",
    "def laplace_prob(w1, w2):\n",
    "    return (counts[(w1, w2)] + 1) / (tokens.count(w1) + vocab_size)\n",
    "\n",
    "print(\"\\nP('sat' | 'cat') =\", laplace_prob('cat', 'sat'))\n",
    "\n",
    "\"\"\"\n",
    "Possible Errors & Fixes:\n",
    "1. LookupError: wordnet not found → Run nltk.download('wordnet')\n",
    "2. IndexError in n-grams → Ensure text length >= n\n",
    "3. ZeroDivisionError → Occurs if token count is 0 → Check tokenization\n",
    "4. Encoding errors in input text → Convert to lowercase and UTF-8\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
